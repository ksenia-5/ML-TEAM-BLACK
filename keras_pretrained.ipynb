{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Image recognition with Keras' pretrained model vgg16 \n",
        "see Keras documentation on [vgg](https://keras.io/api/applications/vgg/)\n",
        "and this [LinkedIn tutorial](https://www.linkedin.com/learning/deep-learning-image-recognition/using-a-pre-trained-network-for-object-recognition?autoplay=true&resume=false)"
      ],
      "metadata": {
        "id": "HaaIihWC32WS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4TqT_1OIxUK9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras.utils as image\n",
        "from keras.applications import vgg16 # pretrained models\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Keras pretrained against ImageNet database\n",
        "model = vgg16.VGG16()\n"
      ],
      "metadata": {
        "id": "hbrPtwc4xkMa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "UxRN4jYK_5-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load image to analyse, resizing to 224x224 pixels (required by this model)\n",
        "img = image.load_img('sample_data/image.png', target_size = (224,224))\n",
        "\n",
        "# convert image to np array\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Add a fourth dimension (Keras expects a list of images)\n",
        "x = np.expand_dims(x,axis=0)\n",
        "\n",
        "# Normalise the input image's pixel values to the range used when training\n",
        "# the neural network (pixel values between 0 and 1)\n",
        "x = vgg16.preprocess_input(x)\n",
        "\n",
        "# Run the image through the neural network to make a prediction\n",
        "predictions = model.predict(x)\n",
        "\n",
        "# Look up names of predicted classes. Index zero is the result for the first image\n",
        "predicted_classes = vgg16.decode_predictions(predictions, top=9)\n",
        "\n",
        "print(\"Top predictions for this image:\")\n",
        "for imagenet_id, name, likelihood in predicted_classes[0]:\n",
        "  print(\"Prediction: {} - {:2f}\".format(name,likelihood))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52XUkbLWycZ1",
        "outputId": "0ad53253-44e8-4c86-c6b6-7eb6a85ab61e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Top predictions for this image:\n",
            "Prediction: remote_control - 0.613027\n",
            "Prediction: mouse - 0.136684\n",
            "Prediction: punching_bag - 0.035909\n",
            "Prediction: microphone - 0.030775\n",
            "Prediction: can_opener - 0.029033\n",
            "Prediction: lipstick - 0.015145\n",
            "Prediction: pick - 0.014140\n",
            "Prediction: modem - 0.013916\n",
            "Prediction: lighter - 0.013488\n"
          ]
        }
      ]
    }
  ]
}